{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "##neural net\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import umap\n",
    "import scipy.stats\n",
    "from scipy.special import softmax\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "\n",
    "from bi_tempered_loss_pytorch import bi_tempered_logistic_loss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1. Define Convolutional neural net of CoSTA, for MERFISH data\n",
    "##\n",
    "class ConvNet_MERFISH(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet_MERFISH, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 128, kernel_size=11,stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128, 128, kernel_size=7,stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(128, 128, kernel_size=5,stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2))\n",
    "        self.dropout = torch.nn.Dropout()\n",
    "        self.fc2 = torch.nn.Linear(128*2*2, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.normalize(out.view(-1, 128*2*2), p=2, dim=1)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "    def forward_feature(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.normalize(out.view(-1, 128*2*2), p=2, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##evalution is the essential function in CoSTA. It performs clustering and generates soft assignment\n",
    "##\n",
    "def evaluation(y_pred,cluster_method=\"Kmeans\",num_cluster = 25,n_neighbors=20,min_dist=0.0):\n",
    "    \n",
    "    if cluster_method==\"Kmeans\":\n",
    "        embedding = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=num_cluster,\n",
    "                              metric=\"euclidean\").fit_transform(y_pred)\n",
    "    \n",
    "        kmeans = KMeans(n_clusters=num_cluster, random_state=1).fit(embedding)\n",
    "        centroid = kmeans.cluster_centers_.copy()\n",
    "        y_label = kmeans.labels_.copy()\n",
    "        y_pseudo=np.zeros((y_pred.shape[0],num_cluster))\n",
    "    elif cluster_method==\"SC\":\n",
    "        embedding = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=num_cluster,\n",
    "                              metric=\"euclidean\").fit_transform(y_pred)\n",
    "        clustering = SpectralClustering(n_clusters=num_cluster,\n",
    "                                        assign_labels=\"discretize\",\n",
    "                                        random_state=0).fit(embedding)\n",
    "        y_label = clustering.labels_.copy()\n",
    "        centroid = pd.DataFrame(embedding.copy())\n",
    "        centroid['label']=y_label\n",
    "        centroid = centroid.groupby('label').mean().values\n",
    "        y_pseudo=np.zeros((y_pred.shape[0],num_cluster))\n",
    "\n",
    "    else:\n",
    "        embedding = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=num_cluster,\n",
    "                              metric=\"euclidean\").fit_transform(y_pred)\n",
    "        gmm = GaussianMixture(n_components=num_cluster).fit(embedding)\n",
    "        y_label = gmm.predict(embedding)\n",
    "        centroid = pd.DataFrame(embedding.copy())\n",
    "        centroid['label']=y_label\n",
    "        centroid = centroid.groupby('label').mean().values\n",
    "\n",
    "        y_pseudo=np.zeros((y_pred.shape[0],num_cluster))\n",
    "    \n",
    "    ##t-student distribution kernel soft-assignment,alpha=1\n",
    "    #for j in range(centroid.shape[0]):\n",
    "    #    y_pseudo[:,j]=(np.linalg.norm(embedding-centroid[j,:],axis=1)+1)**(-1)\n",
    "        ##cosine distance\n",
    "        #y_pseudo[:,j]=((1-cosine_similarity(embedding,centroid[j,:].reshape(1,embedding.shape[1]))+1)**(-1))[:,0]\n",
    "    #y_pseudo = pd.DataFrame(y_pseudo)\n",
    "    #y_pseudo2=np.zeros((y_pred.shape[0],centroid.shape[0]))\n",
    "    #for j in range(centroid.shape[0]):\n",
    "    #    y_pseudo2[:,j]=y_pseudo.iloc[:,j].values/np.sum(\n",
    "    #        y_pseudo[y_pseudo.columns.difference([j])].values,axis=1)\n",
    "    #y_pseudo = y_pseudo2\n",
    "    \n",
    "    ##distance based soft-assignment\n",
    "    for j in range(centroid.shape[0]):\n",
    "        ##euclidean distance\n",
    "        y_pseudo[:,j]=1/np.linalg.norm(embedding-centroid[j,:],axis=1)\n",
    "        ##cosine similarity\n",
    "        #y_pseudo[:,j]=1/(1-cosine_similarity(embedding,centroid[j,:].reshape(1,embedding.shape[1])))[:,0]\n",
    "    y_pseudo=softmax(y_pseudo,axis=1)\n",
    "    \n",
    "    ##auxiliary target distribution\n",
    "    f = np.sum(np.square(y_pseudo)/np.sum(y_pseudo,axis=0),axis=1)\n",
    "    y2 = np.square(y_pseudo)/np.sum(y_pseudo,axis=0)\n",
    "    au_tar = (y2.T/f).T\n",
    "    \n",
    "    return au_tar, y_label,embedding\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform(m.weight.data)\n",
    "        \n",
    "##Use representation learned by CoSTA to find neighbors of genes of interest\n",
    "##\n",
    "def get_neighors(gene_list=None, embedding=None, target=[\"Vim\"]):\n",
    "    embedding = pd.DataFrame(embedding)\n",
    "    embedding.index = gene_list\n",
    "    gene_neighbors={}\n",
    "    for i in target:\n",
    "        distance = np.linalg.norm(embedding.values-embedding.loc[i,:].values,axis=1)\n",
    "        distance = pd.DataFrame(distance)\n",
    "        distance.index=gene_list\n",
    "        distance = distance.sort_values(ascending=True,by=0)\n",
    "        gene_neighbors[i]=distance.index.tolist()[1:51]\n",
    "    return gene_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2. load MERFISH data and reshape into 85X85\n",
    "##\n",
    "gene = pd.read_csv(\"merfish_all_data.csv\",\n",
    "                    header=0,index_col=0)\n",
    "n = gene.shape[0]\n",
    "samples = gene.index.tolist()[-15:]\n",
    "new_X = gene.values.copy().reshape((n,1,85,85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##3. Training CoSTA\n",
    "##\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = ConvNet_MERFISH()\n",
    "net.apply(weights_init)\n",
    "\n",
    "##learning plan\n",
    "t1, t2 = 0.8, 1.2\n",
    "num_epoch = 6\n",
    "batch_size = 170\n",
    "X_all_tensor = torch.tensor(new_X).float()\n",
    "\n",
    "y_pred = net.forward_feature(X_all_tensor)\n",
    "y_pred = torch.Tensor.cpu(y_pred).detach().numpy()\n",
    "au_tar, y_label, embedding = evaluation(y_pred,n_neighbors=5,min_dist=0.0,\n",
    "                                        num_cluster=10,cluster_method='GMM') \n",
    "\n",
    "#opt = torch.optim.SGD(net.parameters(),lr=0.01, momentum=0.9)\n",
    "opt = torch.optim.Adam(net.parameters())\n",
    "\n",
    "##visualization without training\n",
    "original = y_label.copy()\n",
    "embedding = umap.UMAP(n_neighbors=5, min_dist=1, n_components=2,\n",
    "                      metric='correlation').fit_transform(y_pred)\n",
    "\n",
    "embedding = pd.DataFrame(embedding)\n",
    "embedding.columns=['UMAP1','UMAP2']\n",
    "embedding[\"Proton\"]=original\n",
    "f=sns.lmplot(x='UMAP1', y='UMAP2',data=embedding,hue=\"Proton\",\n",
    "             fit_reg=False,legend=False,scatter_kws={'s':15})\n",
    "for i in list(set(y_label)):\n",
    "    plt.annotate(i, \n",
    "                 embedding.loc[embedding['Proton']==i,['UMAP1','UMAP2']].mean(),\n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center',\n",
    "                 size=15, weight='bold')\n",
    "\n",
    "#f.savefig(\"merfish_initial_umap.jpeg\",dpi=450)\n",
    "\n",
    "##Training\n",
    "for k in range(1,num_epoch):\n",
    "    old_label=y_label.copy()\n",
    "    net.to(device)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_X, au_tar, test_size=0.001)\n",
    "    X_tensor=torch.tensor(X_train).float()\n",
    "    y_tensor = torch.tensor(y_train).float()\n",
    "    n = y_train.shape[0]\n",
    "    for j in range(n//batch_size):\n",
    "        inputs = X_tensor[j*batch_size:(j+1)*batch_size,:,:,:].to(device)\n",
    "        outputs = y_tensor[j*batch_size:(j+1)*batch_size,:].to(device)\n",
    "        opt.zero_grad()\n",
    "        output = net.forward(inputs)\n",
    "        #loss = Loss(output, outputs)\n",
    "        loss = bi_tempered_logistic_loss(output, outputs,t1, t2)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    #if k%5==0:\n",
    "    net.to(torch.device(\"cpu\"))\n",
    "    y_pred = net.forward_feature(X_all_tensor)\n",
    "    y_pred = torch.Tensor.cpu(y_pred).detach().numpy()\n",
    "    au_tar, y_label, embedding = evaluation(y_pred,n_neighbors=5,min_dist=0.0,\n",
    "                                            num_cluster=10,cluster_method='GMM') \n",
    "    cm = confusion_matrix(old_label, y_label)\n",
    "    au_tar=au_tar[:,np.argmax(cm,axis=1).tolist()]\n",
    "    nmi = round(normalized_mutual_info_score(old_label, y_label),5)\n",
    "    print(\"NMI\"+\"(\"+str(k)+\"/\"+str(k-1)+\"): \"+str(nmi))\n",
    "        \n",
    "##save model\n",
    "torch.save(net, \"merfish_models\")\n",
    "net = torch.load(\"merfish_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##4. visualization of genes after training\n",
    "##\n",
    "embedding = umap.UMAP(n_neighbors=5, min_dist=1, n_components=2,\n",
    "                      metric='correlation').fit_transform(y_pred)\n",
    "\n",
    "embedding = pd.DataFrame(embedding)\n",
    "embedding.columns=['UMAP1','UMAP2']\n",
    "embedding[\"Proton\"]=original\n",
    "f=sns.lmplot(x='UMAP1', y='UMAP2',data=embedding,hue=\"Proton\",\n",
    "             fit_reg=False,legend=False,scatter_kws={'s':15})\n",
    "for i in list(set(y_label)):\n",
    "    plt.annotate(i, \n",
    "                 embedding.loc[embedding['Proton']==i,['UMAP1','UMAP2']].mean(),\n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center',\n",
    "                 size=15, weight='bold')\n",
    "#f.savefig(\"merfish_trained_umap.jpeg\",dpi=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##5. Permutation test to identify SE genes\n",
    "##\n",
    "new_y_pred=pd.DataFrame(y_pred.copy())\n",
    "new_y_pred.index = gene.index\n",
    "net.to(torch.device(\"cpu\"))\n",
    "sub_X = new_X.copy().reshape(176,85*85)\n",
    "sub_X = pd.DataFrame(sub_X)\n",
    "sub_X.index = gene.index\n",
    "SE_genes_hi = {}\n",
    "SE_genes_low = {}\n",
    "SE_genes_med = {}\n",
    "for i in samples:\n",
    "    SE_genes_hi[i]=[]\n",
    "    SE_genes_low[i]=[]\n",
    "    SE_genes_med[i]=[]\n",
    "    if i in gene.index:\n",
    "        for j in gene.index.tolist():\n",
    "            if j not in samples:\n",
    "                null = np.zeros((101,85*85))\n",
    "                null[0,:]=sub_X.loc[j,:].values.copy()\n",
    "                for k in range(1,101):\n",
    "                    g = sub_X.loc[j,:].values.copy()\n",
    "                    np.random.shuffle(np.transpose(g))\n",
    "                    null[k,:]= g\n",
    "                null = null.reshape(101,1,85,85)\n",
    "                X_tensor = torch.tensor(null).float()\n",
    "                y_pred = net.forward_feature(X_tensor)\n",
    "                y_pred = torch.Tensor.cpu(y_pred).detach().numpy()\n",
    "                distance = np.linalg.norm(y_pred-new_y_pred.loc[i,:].values,axis=1)\n",
    "                zscore=scipy.stats.zscore(distance)\n",
    "                if zscore[0]<-1.645:\n",
    "                    SE_genes_low[i].append(j)\n",
    "                if zscore[0]<-2.325:\n",
    "                    SE_genes_med[i].append(j)\n",
    "                if zscore[0]<-3.1:\n",
    "                    SE_genes_hi[i].append(j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
